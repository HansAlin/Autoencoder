{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 2  will be allocated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gpuutils import GpuUtils\n",
    "GpuUtils.allocate(gpu_count=1, framework='keras')\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "from gc import callbacks\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, UpSampling1D\n",
    "#from keras_flops import get_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing_data(signal, noise):\n",
    "  \"\"\"\n",
    "    This function normalize the data using mean and standard\n",
    "    deviation from noise data\n",
    "  \"\"\"\n",
    "  std = np.std(noise)\n",
    "  mean = np.mean(noise)\n",
    "  normalized_noise = (noise - mean)/std\n",
    "  normalized_signal = (signal - mean)/std\n",
    "  \n",
    "  return normalized_noise, normalized_signal, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalizing_data(normalized_data, std, mean):\n",
    "  data = normalized_data*std + mean\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(all_signals=True):\n",
    "  \"\"\"\n",
    "    This function loads data from ARIANNA group, downloaded localy\n",
    "    Args:\n",
    "     all_signals = True means that all the signals are\n",
    "    used in the test data. If all_signals = False only 20000 signals are used as test data.\n",
    "    Can be useful if training on signals aswell or just want to test data on small\n",
    "    test data.\n",
    "    Returns:\n",
    "      x_test, y_test, smask_test, signal, noise, std, mean\n",
    "    \n",
    "  \"\"\"\n",
    "  DATA_URL = '/home/halin/Autoencoder/Data/trimmed100_data_noise_3.6SNR_1ch_0000.npy'#/home/halin/Autoencoder/Data/trimmed100_data_noise_3.6SNR_1ch_0000.npy\n",
    "  noise = np.load(DATA_URL)\n",
    "\n",
    "  for i in range(1,10):\n",
    "    noise = np.vstack((noise,np.load(f'/home/halin/Autoencoder/Data/trimmed100_data_noise_3.6SNR_1ch_000{i}.npy')))\n",
    "\n",
    "  noise = np.vstack((noise,np.load('/home/halin/Autoencoder/Data/trimmed100_data_noise_3.6SNR_1ch_0010.npy')))\n",
    "  signal = np.load(\"/home/halin/Autoencoder/Data/trimmed100_data_signal_3.6SNR_1ch_0000.npy\")\n",
    "  signal = np.vstack((signal,np.load(\"/home/halin/Autoencoder/Data/trimmed100_data_signal_3.6SNR_1ch_0001.npy\")))\n",
    "  n_classes = 2\n",
    " \n",
    "  noise, signal, std, mean = normalizing_data(signal, noise)\n",
    "\n",
    "  shuffle = np.arange(noise.shape[0], dtype=np.int)\n",
    "  np.random.shuffle(shuffle)\n",
    "  noise = noise[shuffle]\n",
    "  shuffle = np.arange(signal.shape[0], dtype=np.int)\n",
    "  np.random.shuffle(shuffle)\n",
    "  signal = signal[shuffle]\n",
    "\n",
    "  number_of_test_samples = 0\n",
    "  if all_signals:\n",
    "    number_of_test_samples = len(signal)\n",
    "  else:  \n",
    "    number_of_test_samples = 20000\n",
    "\n",
    "  \n",
    "\n",
    "  signal_test = signal[:number_of_test_samples]\n",
    "  noise_test = noise[:number_of_test_samples*2]\n",
    "  \n",
    "  signal = signal[number_of_test_samples:]\n",
    "  noise = noise[number_of_test_samples*2:]\n",
    "\n",
    "  x_test = np.vstack((noise_test, signal_test))\n",
    "  x_test = np.expand_dims(x_test, axis=-1)\n",
    "  y_test = np.ones(len(x_test))\n",
    "  y_test[:len(noise_test)] = 0\n",
    "  shuffle = np.arange(x_test.shape[0])  #, dtype=np.int\n",
    "  np.random.shuffle(shuffle)\n",
    "  x_test = x_test[shuffle]\n",
    "  y_test = y_test[shuffle]\n",
    "  smask_test = y_test == 1\n",
    "\n",
    "  return x_test, y_test, smask_test, signal, noise, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_signal(model, treshold, x, smask, under_treshold=True):\n",
    "  \"\"\"\n",
    "    This function steps trough the losses to find data tha are\n",
    "    below or above a sertain treshold.\n",
    "    Args:\n",
    "      model: keras model\n",
    "      treshold: (float) value to compare\n",
    "      x: data to test\n",
    "      smask: where the true signals are\n",
    "      under_treshold: (bool)\n",
    "    Returns:\n",
    "      outliers: the data beyond threshold in an list\n",
    "\n",
    "  \"\"\"\n",
    "  outliers = []\n",
    "  for i in range(len(x)):\n",
    "    x_pred = model.predict(np.array([x[i],]))\n",
    "    test = x[i]\n",
    "    pred_loss = keras.losses.mean_squared_error(x[i], x_pred)\n",
    "    pred_loss = np.sum(pred_loss)/len(pred_loss)\n",
    "    if under_treshold:\n",
    "      if pred_loss < treshold:\n",
    "        outliers.append(x[i])\n",
    "        \n",
    "    else:\n",
    "      if pred_loss > treshold:\n",
    "        outliers.append(x[i])  \n",
    "  return outliers      \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(signal, noise, signal_ratio=0.001, test_run=False ):\n",
    "  \"\"\"\n",
    "    This function creates training(validation) and test data based on choosen \n",
    "    signal ratio in sample.\n",
    "    Args:\n",
    "      signal = samples with signal\n",
    "      noise = samples with noise\n",
    "      test_run = creates a small training batch just for testing rest of code\n",
    "    Returns:\n",
    "      x_train, smask_train, y_train, x_test, smask_test, y_test\n",
    "      \n",
    "  \"\"\"\n",
    "  \n",
    "  mini_batch_size = 10000\n",
    "  number_of_noise_samples = np.size(noise[:,0])\n",
    "\n",
    "  if test_run:\n",
    "    noise_train = noise[:mini_batch_size]\n",
    "    signal_train = signal[:mini_batch_size]\n",
    "  else:  \n",
    "    noise_train = noise\n",
    "    number_of_train_signals = np.floor((number_of_noise_samples)*signal_ratio).astype(int)\n",
    "    signal_train = signal[:number_of_train_signals]\n",
    "\n",
    "\n",
    "\n",
    "  x_train = np.vstack((noise_train, signal_train))\n",
    "  x_train = np.expand_dims(x_train, axis=-1)\n",
    "  y_train = np.ones(len(x_train))\n",
    "  y_train[:len(noise_train)] = 0\n",
    "  shuffle = np.arange(x_train.shape[0]) #, dtype=np.int\n",
    "  np.random.shuffle(shuffle)\n",
    "  x_train = x_train[shuffle]\n",
    "  y_train = y_train[shuffle]\n",
    "  smask_train = y_train == 1\n",
    "\n",
    "  \n",
    "\n",
    "  return x_train, smask_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a few signal events\n",
    "# TODO \n",
    "def plot_signal_nois(x,smask):\n",
    "  for trace in x[smask][:2]:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(trace)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # plot a few noise events\n",
    "  for noise in x[~smask][:2]:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(noise)\n",
    "    fig.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input, kernel=3, latent_space=6, filter_size=128, layers=2):\n",
    "  layer = input\n",
    "  maxpooling_size = 2\n",
    "  for i in range(layers):\n",
    "    layer = Conv1D(filter_size, kernel , activation='relu', padding='same')(layer)\n",
    "    if i ==2:\n",
    "      maxpooling_size = 5\n",
    "    else:\n",
    "      maxpooling_size = 2  \n",
    "    layer = MaxPooling1D(maxpooling_size, padding='same' )(layer)\n",
    "\n",
    "  layer = Flatten()(layer)\n",
    "  layer = Dense(latent_space)(layer)\n",
    "\n",
    "  encoded = layer\n",
    "\n",
    "  return encoded  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(input, kernel=3, latent_space=6, filter_size=128, layers=2):\n",
    "  layer = input\n",
    "  data_size = len(x_test[0])\n",
    "  \n",
    "  size_of_first_feature = np.int(data_size / 2**layers)\n",
    "  if layers == 3:\n",
    "    size_of_first_feature = np.int(data_size / (2*2*5))\n",
    "  \n",
    "  upsampling_size = 2\n",
    "  \n",
    "  layer = Dense((filter_size * size_of_first_feature),activation='relu')(layer)\n",
    "  layer = Reshape((size_of_first_feature,filter_size))(layer)\n",
    "\n",
    "  for i in range(layers):\n",
    "    layer = Conv1D(filter_size, kernel, activation='relu', padding='same')(layer)\n",
    "    if layers == 3 and i == 0:\n",
    "      upsampling_size = 5\n",
    "    else:\n",
    "      upsampling_size = 2  \n",
    "    layer = UpSampling1D(upsampling_size)(layer)\n",
    "\n",
    "  layer = Conv1D(1, kernel, activation='tanh', padding='same', name='layer9')(layer)\n",
    "  \n",
    "  return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input, kernel, latent_space, filter_size, layers):\n",
    "  enc = encoder(input, kernel, latent_space, filter_size, layers)\n",
    "  autoencoder = decoder(enc, kernel, latent_space, filter_size, layers )\n",
    "  return autoencoder\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder_model(data, kernel, latent_space,  filter_size, layers, learning_rate=0.0005,):\n",
    "\n",
    "  adam = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  input_data = keras.Input(shape=data[1].shape, name='first_layer')\n",
    "  \n",
    "  model = keras.Model(inputs=input_data, outputs=autoencoder(input_data, kernel, latent_space, filter_size=filter_size, layers=layers))\n",
    "  model.compile(\n",
    "      loss = 'mse',\n",
    "      optimizer = adam,\n",
    "      metrics = ['mse','mae','mape']   \n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def  train_autoencoder(model, x_train, epochs=50, batch=16, verbose=0):\n",
    "  early_stopping = keras.callbacks.EarlyStopping(\n",
    "                                    monitor=\"mse\",\n",
    "                                    min_delta=0,\n",
    "                                    patience=5,\n",
    "                                    verbose=0,\n",
    "                                    mode=\"auto\",\n",
    "                                    baseline=None,\n",
    "                                    restore_best_weights=True,\n",
    "                                )\n",
    "\n",
    "  val_split = 0.2\n",
    "  autoencoder = model.fit(x = x_train,\n",
    "                          y = x_train,\n",
    "                          epochs=epochs,\n",
    "                          batch_size = batch,\n",
    "                          verbose=verbose,\n",
    "                          shuffle = True,\n",
    "                          validation_split = val_split,\n",
    "                          callbacks=early_stopping\n",
    "                          )\n",
    "  return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(path, trained_autoencoder):\n",
    "  loss = trained_autoencoder.history['loss']\n",
    "  val_loss = trained_autoencoder.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.yscale('log')\n",
    "  plt.legend()\n",
    "  path = path + '_loss_plot.png'\n",
    "  plt.savefig(path)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(x):\n",
    "  for item in x:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(item)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_loss_values(model, x, smask):\n",
    "  \"\"\"\n",
    "    This function predict the value using keras.predict and\n",
    "    calculates the mse for signals and noise events. Add the values \n",
    "    and divide by sample size\n",
    "    Args:\n",
    "      model: keras model\n",
    "      x: the test data shape (Any, 100, 1)\n",
    "      smask: smask for x \n",
    "    Returns: \n",
    "      signal_loss, noise_loss \n",
    "  \"\"\"\n",
    "  data_bins = np.size(x[0])\n",
    "  x_noise = x[~smask]\n",
    "  x_pred_noise = model.predict(x_noise)\n",
    "  x_signal = x[smask]\n",
    "  x_pred_signal = model.predict(x_signal)\n",
    "  noise_loss = keras.losses.mean_squared_error(x_noise, x_pred_noise)\n",
    "  noise_loss = np.sum(noise_loss, axis=1)/data_bins     #Per sample bin\n",
    "\n",
    "  signal_loss = keras.losses.mean_squared_error(x_signal, x_pred_signal)\n",
    "  signal_loss = np.sum(signal_loss, axis=1)/data_bins\n",
    "\n",
    "  return signal_loss, noise_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(path, signal_loss, noise_loss, resolution=100, plot=True):\n",
    "  max_value = np.max(signal_loss)\n",
    "  min_value = np.min(noise_loss)\n",
    "  low_lim = np.floor(np.log10(min_value))\n",
    "  high_lim = np.floor(np.log10(max_value))\n",
    "  bins = np.logspace(low_lim,high_lim , resolution)\n",
    "\n",
    "  if plot:\n",
    "    \n",
    "    ax1 = plt.hist(noise_loss, bins=bins, log=True, alpha=0.5, density=True)\n",
    "    ax2 = plt.hist(signal_loss, bins=bins, log=True, alpha=0.5, density=True)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Mean squared error')\n",
    "    plt.ylabel('Counts')\n",
    "    path = path + '_hist.png'\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "  return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(path, signal_loss, noise_loss, bins,fpr=0.05, plot=True):\n",
    "  \"\"\"\n",
    "    This function takes signal and noise loss as arguments. They are \n",
    "    arrays from mse calculating.\n",
    "    Bins is taken from hist\n",
    "    Args: \n",
    "      path: where the plots saves\n",
    "      signal_loss: calculated signal loss\n",
    "      noise_loss: noise loss\n",
    "      bins: number of bins to split the data\n",
    "      fpr: False Positive Rate \n",
    "    Returns:\n",
    "      thershold: value for a specific False Positive Ratio fpr\n",
    "      tpr: True positive ratio \n",
    "      fpr: False positive ratio\n",
    "      tnr: True negative ratio\n",
    "      fnr: False negative ratio\n",
    "\n",
    "  \"\"\"\n",
    "  min_value = np.min(signal_loss)\n",
    "  max_value = np.max(signal_loss)\n",
    "\n",
    "  thresholds = bins\n",
    "  threshold_value = 0\n",
    "  true_pos = np.zeros(len(bins))\n",
    "  false_pos = np.zeros(len(bins))\n",
    "  i = 0\n",
    "\n",
    "  tpr = 0\n",
    "  for limit in thresholds:\n",
    "    true_pos[i] = np.count_nonzero(signal_loss > limit)/len(signal_loss)\n",
    "    false_pos[i] =np.count_nonzero(noise_loss > limit)/len(noise_loss)\n",
    "    if false_pos[i-1] > fpr :\n",
    "      threshold_value = limit\n",
    "      tpr = true_pos[i]\n",
    "\n",
    "    i += 1\n",
    "\n",
    "  fnr = 1 - tpr\n",
    "  tnr = 1 - fpr  \n",
    "  \n",
    "\n",
    "  if plot:\n",
    "    plt.plot(false_pos,true_pos)  \n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.title('ROC')\n",
    "\n",
    "    ## Vertical line at False Positive Rate limit\n",
    "    y = np.linspace(0,1,2)\n",
    "    x = [fpr]*2\n",
    "    plt.plot(x,y)\n",
    "\n",
    "    plt.grid()\n",
    "    path = path + '_roc.png'\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "\n",
    "  return threshold_value, tpr, fpr, tnr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction_curve(path, signal_loss, noise_loss, fpr=0.05, plot=True):\n",
    "  \"\"\"\n",
    "    This function takes signal and noise loss as arguments. They are \n",
    "    arrays from mse calculating.\n",
    "    Bins is taken from hist\n",
    "    Args: \n",
    "      path: where the plots saves\n",
    "      signal_loss: calculated signal loss\n",
    "      noise_loss: noise loss\n",
    "      fpr: False Positive Rate \n",
    "    Returns:\n",
    "      thershold: value for a specific False Positive Ratio fpr\n",
    "      tpr: True positive ratio \n",
    "      fpr: False positive ratio\n",
    "      tnr: True negative ratio\n",
    "      fnr: False negative ratio\n",
    "\n",
    "  \"\"\"\n",
    "  max_value = np.max(signal_loss)\n",
    "  min_value = np.min(noise_loss)\n",
    "  low_lim = np.floor(np.log10(min_value))\n",
    "  high_lim = np.floor(np.log10(max_value))\n",
    "  bins = np.logspace(low_lim,high_lim , 1000)\n",
    "\n",
    "  \n",
    "  threshold_value = 0\n",
    "  true_pos = np.zeros(len(bins))\n",
    "  false_pos = np.zeros(len(bins))\n",
    "  true_neg = np.zeros(len(bins))\n",
    "  false_neg = np.zeros(len(bins))\n",
    "  noise_reduction_factor = np.zeros(len(bins))\n",
    "\n",
    "\n",
    "  tpr = 0\n",
    "  for i, limit in enumerate(bins):\n",
    "    \n",
    "    true_pos[i] = np.count_nonzero(signal_loss > limit)/len(signal_loss)\n",
    "    false_pos[i] =np.count_nonzero(noise_loss > limit)/len(noise_loss)\n",
    "    true_neg[i] = 1 - false_pos[i]\n",
    "    false_neg[i] = 1 - true_pos[i]\n",
    "    \n",
    "\n",
    "    if (true_neg[i] < 1):\n",
    "      noise_reduction_factor[i] = 1 / ( 1 - true_neg[i])\n",
    "    else:\n",
    "      noise_reduction_factor[i] = len(noise_loss)  \n",
    "    \n",
    "    \n",
    "    if false_pos[i] > fpr:\n",
    "      threshold_value = limit\n",
    "      tpr = true_pos[i]\n",
    "\n",
    "\n",
    "  fnr = 1 - tpr\n",
    "  tnr = 1 - fpr  \n",
    "\n",
    "  if plot:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "    ax.plot(true_pos,noise_reduction_factor)  \n",
    "    ax.set_ylabel(f'Noise reduction factor. Total {len(noise_loss)} noise events')\n",
    "    ax.set_xlabel('Efficiency/True Positive Rate')\n",
    "    ax.set_title('Signal efficiency vs. noise reduction factor')\n",
    "    ax.semilogy(True)\n",
    "    ax.set_xlim(0.875,1)\n",
    "    ax.grid()\n",
    "    path = path + '_Signal_efficiency_vs_noise_reduction_factor.png'\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    plt.show()\n",
    "    # plt.plot(false_pos, true_pos)\n",
    "    # plt.show()\n",
    "  return threshold_value, tpr, fpr, tnr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "# * Confusion matrix\n",
    "# * pic the threshold value for a specific FPR\n",
    "# * Hyper paramters \n",
    "# * bach\n",
    "# * epochs\n",
    "# * learning rate\n",
    "# * ratio of signal / noise  events\n",
    "# * \n",
    "# * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(threshold_value, tpr, fpr, tnr, fnr):\n",
    "  from tabulate import tabulate\n",
    "\n",
    "  tabel = [['', 'Data-with-signals', 'Data-without-signal'],\n",
    "           ['Signal detected', f'{tpr:.2f}', fpr],\n",
    "           ['Noise detected', f'{fnr:.2f}', tnr]]\n",
    "  print(f'Confusion matrix with threshold value at {threshold_value:.2e}')  \n",
    "  print(tabulate(tabel, headers='firstrow'))         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model\n",
    "def find_best_model(path,fpr,save_output=True):\n",
    "  \"\"\"\n",
    "    This finction steps trough the file results.csv for finding the\n",
    "    best model based on what model have the higest true positive rate \n",
    "    when false positive is equal to fpr, normaly 0.05\n",
    "    Args:\n",
    "      path: in what folder to search in\n",
    "      fpr: false positive rate\n",
    "      save_output:\n",
    "      \n",
    "  \"\"\"\n",
    "  results_path = path + '/' + 'results.csv'\n",
    "  results = pd.read_csv(results_path)\n",
    "\n",
    "  print(results)\n",
    "  column = results['True pos.']\n",
    "  index_of_max = column.idxmax()\n",
    "  best_model = results.iloc[index_of_max]  \n",
    "  \n",
    "\n",
    "  model_path = path + '/' + best_model['Model name'] + '.h5'\n",
    "  model = load_model(model_path)\n",
    "\n",
    "  signal_loss, noise_loss = prep_loss_values(model,x_test,smask_test)\n",
    "  _ = hist(path + '/' + 'best_model', signal_loss, noise_loss, plot=True)\n",
    "  threshold_value, tpr, fpr, tnr, fnr, noise_reduction_factor = noise_reduction_curve_multi_models([model], path+ '/' + 'best_model',save_outputs = save_output, fpr=fpr, plot=True )\n",
    "  confusion_matrix(threshold_value, tpr, fpr, tnr, fnr)\n",
    "  if save_output:\n",
    "    model.save((path + '/' + 'best_model'+ '.h5'))\n",
    "  print(best_model['False pos.'])\n",
    "  best_model['False pos.'] = fpr\n",
    "  print(best_model['False pos.'])\n",
    "  best_model['True pos.'] = tpr\n",
    "  print(best_model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise reduction curve multi models\n",
    "def noise_reduction_curve_multi_models(models, path, fpr, plot=True, x_low_lim=0.8, save_outputs=True, models_to_plot=[]):\n",
    "  \"\"\"\n",
    "    This function takes signal and noise loss as arguments. They are \n",
    "    arrays from mse calculating.\n",
    "    Bins is taken from hist\n",
    "    Args: \n",
    "      models: a list of keras models\n",
    "      path: where the plots saves\n",
    "      fpr: False Positive Rate \n",
    "      x_low_lim: limit for lowest x value on plot (highest=1)\n",
    "    Returns:\n",
    "      thershold: value for a specific False Positive Ratio fpr for best model\n",
    "      tpr: True positive ratio for best model\n",
    "      fpr: False positive ratio for best model\n",
    "      tnr: True negative ratio for best model\n",
    "      fnr: False negative ratio for best model\n",
    "      results[0][4]: noise reduction factor for first model\n",
    "\n",
    "  \"\"\"\n",
    "  number_of_models = len(models)\n",
    "  results = [0]*number_of_models\n",
    "  for j in range(number_of_models):\n",
    "    \n",
    "    model = models[j]\n",
    "    not_found_treshold_value = True\n",
    "    signal_loss, noise_loss = prep_loss_values(model, x_test, smask_test)\n",
    "    \n",
    "    max_value = np.max(signal_loss)\n",
    "    min_value = np.min(noise_loss)\n",
    "    low_lim = np.floor(np.log10(min_value))\n",
    "    high_lim = np.floor(np.log10(max_value))\n",
    "    bins = np.logspace(low_lim,high_lim , 1000)\n",
    "\n",
    "\n",
    "    threshold_value = 0\n",
    "    true_pos = np.zeros(len(bins))\n",
    "    false_pos = np.zeros(len(bins))\n",
    "    true_neg = np.zeros(len(bins))\n",
    "    false_neg = np.zeros(len(bins))\n",
    "    noise_reduction_factor = np.zeros(len(bins))\n",
    "\n",
    "\n",
    "    tpr = 0\n",
    "    for i, limit in enumerate(bins):\n",
    "    \n",
    "      true_pos[i] = np.count_nonzero(signal_loss > limit)/len(signal_loss)\n",
    "      false_pos[i] =np.count_nonzero(noise_loss > limit)/len(noise_loss)\n",
    "      true_neg[i] = 1 - false_pos[i]\n",
    "      false_neg[i] = 1 - true_pos[i]\n",
    "    \n",
    "\n",
    "      if (true_neg[i] < 1):\n",
    "        noise_reduction_factor[i] = 1 / ( 1 - true_neg[i])\n",
    "      else:\n",
    "        noise_reduction_factor[i] = len(noise_loss)  \n",
    "      \n",
    "      \n",
    "      if false_pos[i] < fpr and not_found_treshold_value:\n",
    "        threshold_value = limit\n",
    "        tpr = true_pos[i]\n",
    "        not_found_treshold_value = False\n",
    "        \n",
    "\n",
    "\n",
    "    fnr = 1 - tpr\n",
    "    tnr = 1 - fpr\n",
    "    \n",
    "\n",
    "    results[j] = [true_pos, true_neg, false_pos, false_neg, noise_reduction_factor]\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "  if plot:\n",
    "    if len(models_to_plot) < 1:\n",
    "      models_to_plot = np.arange(0,len(models))\n",
    "\n",
    "    for k in models_to_plot:\n",
    "      model_name = 'model ' + str(k+1)\n",
    "      plt.plot(results[k][0],results[k][4], label=model_name)  \n",
    "      \n",
    "    noise_events = np.count_nonzero(~smask_test)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel(f'Noise reduction factor. Total {noise_events} noise events')\n",
    "    plt.xlabel('Efficiency/True Positive Rate')\n",
    "    plt.title('Signal efficiency vs. noise reduction factor')\n",
    "    plt.semilogy(True)\n",
    "    plt.xlim(x_low_lim,1)\n",
    "    plt.grid()\n",
    "    if len(models) > 1:\n",
    "      path = path + '/Signal_efficiency_vs_noise_reduction_factor_all_models.png'\n",
    "    else:\n",
    "      path = path + '_Signal_efficiency_vs_noise_reduction_factor.png'  \n",
    "    plt.tight_layout()\n",
    "    if save_outputs:\n",
    "      plt.savefig(path)\n",
    "\n",
    "    plt.show()\n",
    "  # plt.plot(false_pos, true_pos)\n",
    "  # plt.show()\n",
    "\n",
    "  return threshold_value, tpr, fpr, tnr, fnr, results[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "def create_and_train_model(layers, model_number, latent_space, test_run, path, signal, noise, verbose, kernel, epochs=5, batch=256, learning_rate=0.0005, signal_ratio=1, plot=False, fpr=0.05, number_of_filters=128):\n",
    "  model_name = 'model_' + str(model_number)\n",
    "  print(model_name)\n",
    "  path = path + '/' + model_name\n",
    "\n",
    "  x_train, smask_train, y_train = create_data(signal, noise, signal_ratio=signal_ratio, test_run=test_run )\n",
    "  autoencoder_model = create_autoencoder_model(x_train, kernel=kernel, latent_space=latent_space, filter_size=number_of_filters, layers=layers, learning_rate=learning_rate )\n",
    "  autoencoder_model.summary()\n",
    "  #keras.utils.plot_model(autoencoder_model, to_file=(path + '.jpg'), show_layer_activations=True, show_dtype=True, show_shapes=True)\n",
    "  trained_autoencoder = train_autoencoder(autoencoder_model,x_train, epochs, batch, verbose)\n",
    "  signal_loss, noise_loss = prep_loss_values(autoencoder_model,x_test,smask_test)\n",
    "  if plot:\n",
    "    loss_plot(path, trained_autoencoder)\n",
    "  bins = hist(path, signal_loss, noise_loss, plot=plot)\n",
    "  threshold_value, tpr, fpr, tnr, fnr, noise_reduction_factors = noise_reduction_curve_multi_models([autoencoder_model],path, fpr=fpr, plot=plot)\n",
    "\n",
    "  flops = 0#get_flops(autoencoder_model)\n",
    "  #TODO get flops to work\n",
    "  autoencoder_model.save((path + '.h5'))\n",
    "\n",
    "  return model_name, epochs, batch, kernel, learning_rate, signal_ratio, fpr, tpr, threshold_value, latent_space, number_of_filters, flops, layers, noise_reduction_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_models(path):\n",
    "  \"\"\"\n",
    "    This function search for keras models in an folder and loads\n",
    "    it to a list en returns a list of models. Models which contains \n",
    "    the substring \"best_model\" are excluded.\n",
    "    Args:\n",
    "      path: were to search for models\n",
    "  \"\"\"\n",
    "  import glob\n",
    "  list_of_models = glob.glob(path + '/*.h5')\n",
    "  models = []\n",
    "  for i, path in enumerate(list_of_models):\n",
    "    if 'best_model' in path:\n",
    "      pass\n",
    "    else: \n",
    "      models.append(load_model(path))\n",
    "\n",
    "  return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batches = [512]\n",
    "learning_rates = [10**(-3), 10**(-4), 10**(-5)]\n",
    "signal_ratios = [0]\n",
    "kernels = [3]\n",
    "latent_spaces = [2]\n",
    "number_of_filters = [128]\n",
    "layers = [1]\n",
    "epochs = 1\n",
    "\n",
    "model_number = 1\n",
    "test_run = True\n",
    "all_signals = False\n",
    "plot =True\n",
    "fpr = 0.05\n",
    "verbose = 0\n",
    "\n",
    "x_test, y_test, smask_test, signal, noise, std, mean = load_data(all_signals=all_signals)\n",
    "results = pd.DataFrame(columns=[ 'Model name', 'Epochs', 'Batch', 'Kernel', 'Learning rate', 'Signal ratio', 'False pos.', 'True pos.', 'Threshold value', 'Latent space', 'Number of filters', 'Flops', 'Layers', 'Noise reduction'])\n",
    "path = '/home/halin/Autoencoder/Models/CNN_008'\n",
    "\n",
    "\n",
    "\n",
    "for batch in batches:\n",
    "  for learning_rate in learning_rates:\n",
    "    for signal_ratio in signal_ratios:\n",
    "      for kernel in kernels:\n",
    "        for latent_space in latent_spaces:\n",
    "          for filters in number_of_filters:\n",
    "            for layer in layers:\n",
    "              results.loc[model_number] = create_and_train_model(layers=layer,\n",
    "                                                               model_number=model_number,\n",
    "                                                              latent_space=latent_space,\n",
    "                                                              test_run=test_run,\n",
    "                                                              path=path,\n",
    "                                                              signal=signal,\n",
    "                                                              noise=noise,\n",
    "                                                              verbose=verbose,\n",
    "                                                              kernel=kernel,\n",
    "                                                              epochs=epochs,\n",
    "                                                              batch=batch,\n",
    "                                                              learning_rate=learning_rate,\n",
    "                                                              signal_ratio=signal_ratio, \n",
    "                                                              plot=plot,\n",
    "                                                              fpr=fpr,\n",
    "                                                              number_of_filters=filters)\n",
    "              model_number += 1\n",
    "\n",
    "\n",
    "results.to_csv(path + '/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test, y_test, smask_test, signal, noise, std, mean = load_data(all_signals=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_model(path,  fpr=0.05, save_output=False)\n",
    "models = load_models(path)\n",
    "_ = noise_reduction_curve_multi_models(models,path, 0.05, x_low_lim=0.8)#, models_to_plot=[3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/halin/Autoencoder/Models/CNN_001'\n",
    "# models = load_models(path)\n",
    "# results_path = path + '/' + 'results_test.csv'\n",
    "# results = pd.read_csv(results_path)\n",
    "# results['Noise reduction'] = results['Noise reduction'].astype('object')\n",
    "# for i, model in enumerate(models):\n",
    "#   threshold_value, tpr, fpr, tnr, fnr, noise_reduction_factor = noise_reduction_curve_multi_models([model],path, fpr=0.05, save_outputs=False)\n",
    "  \n",
    "#   results.loc[[i], ['True pos.']] = tpr\n",
    "#   results.at[i,'Noise reduction'] = noise_reduction_factor\n",
    "\n",
    "# results.to_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_table(path, table_name='results.csv', headers=[ 'Model name', 'Epochs', 'Batch', 'Kernel', 'Learning rate', 'Signal ratio', 'False pos.', 'True pos.', 'Latent space', 'Flops', 'Layers']):\n",
    "  \"\"\"\n",
    "    This function plots the result from the atempt. The results are pandas dataframe.\n",
    "    Args:\n",
    "      path: Where the dataframe is stored\n",
    "      table_name: name on the file with the result\n",
    "      headers: The columns that is going to be plotted\n",
    "  \"\"\"\n",
    "  atempt = path[-7:]\n",
    "  result_path = path + '/' + table_name\n",
    "  results = pd.read_csv(result_path)\n",
    "  fig, ax = plt.subplots()#1,1, figsize=(12,4)\n",
    "  #fig.patch.set_visible(False)\n",
    "\n",
    "\n",
    "  ax.axis('off')\n",
    "  ax.axis('tight')\n",
    "  table = ax.table( cellText=results[headers].values,\n",
    "                    colLabels=results[headers].columns,\n",
    "                    loc='center'\n",
    "                    )\n",
    "  #table.auto_set_font_size(False)                    \n",
    "  table.set_fontsize(10)                    \n",
    "  table.scale(20, 1)   \n",
    "  table.auto_set_column_width(col=list(range(len(results[headers].columns))))                 \n",
    "  ax.set_title(f'Hyperparameters from {atempt} ', \n",
    "              fontweight =\"bold\")                     \n",
    "  fig.tight_layout()\n",
    "\n",
    "  savefig_path = path + '/' + atempt + '_table.png'\n",
    "  plt.savefig(savefig_path,\n",
    "              bbox_inches='tight',\n",
    "              edgecolor=fig.get_edgecolor(),\n",
    "              facecolor=fig.get_facecolor(),\n",
    "              dpi=150 )\n",
    "  plt.show()                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_table( path = path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00e6b041018f9c5003ba88af84c1401696fe75920157f0e0f441a09854937f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
